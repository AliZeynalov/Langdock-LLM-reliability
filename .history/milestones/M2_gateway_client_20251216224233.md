# M2: Gateway + Simple Client

**Goal:** Build the gateway server that receives requests and forwards them to a provider.

**Time:** 3-4 hours  
**Output:** Gateway on :8080 that forwards to mock provider on :8001

---

## What We're Building

```
┌──────────┐      ┌──────────────┐      ┌───────────────┐
│  Client  │ ──── │   Gateway    │ ──── │ Mock Provider │
│  (curl)  │      │   (:8080)    │      │   (:8001)     │
└──────────┘      └──────────────┘      └───────────────┘
                         │
                  • Request ID middleware
                  • Structured logging
                  • Provider client
```

---

## Key Concepts

### 1. Request ID Middleware

Every request gets a unique ID that travels through the entire lifecycle.

```go
// internal/gateway/middleware.go

func RequestIDMiddleware() gin.HandlerFunc {
    return func(c *gin.Context) {
        // Generate unique ID: "req_a1b2c3d4"
        requestID := "req_" + uuid.New().String()[:8]
        
        // Store in Gin context (accessible throughout request)
        c.Set("request_id", requestID)
        
        // Also return in response header (for client debugging)
        c.Header("X-Request-ID", requestID)
        
        // Continue to next middleware/handler
        c.Next()
    }
}
```

**Why this matters:** When you see logs, you can grep by request_id to see the entire journey of one request.

### 2. Go Context for Passing Values

Go's `context.Context` is the standard way to pass request-scoped values:

```go
// How to pass request_id through layers
func (h *Handler) ChatCompletion(c *gin.Context) {
    // Get from Gin context
    requestID := c.GetString("request_id")
    
    // Create Go context with the ID
    ctx := context.WithValue(c.Request.Context(), "request_id", requestID)
    
    // Pass to provider client
    response, err := h.providerClient.Call(ctx, request)
}
```

### 3. Structured Logging with Logrus

Instead of `fmt.Println`, use structured logs:

```go
import log "github.com/sirupsen/logrus"

// Bad - hard to parse
fmt.Println("Request received for model gpt-4")

// Good - structured, searchable
log.WithFields(log.Fields{
    "request_id": requestID,
    "model":      request.Model,
    "event":      "received",
}).Info("Request received")

// Output:
// INFO[0000] Request received  event=received model=gpt-4 request_id=req_a1b2c3
```

---

## File Structure

```
cmd/
    server/
        main.go              # Gateway entry point

internal/
    gateway/
        middleware.go        # Request ID, logging middleware
        handler.go           # HTTP handlers
    provider/
        client.go            # HTTP client to call providers
    models/
        request.go           # Already exists
```

---

## Implementation Steps

### Step 1: Gateway Entry Point

```go
// cmd/server/main.go
package main

import (
    "github.com/gin-gonic/gin"
    log "github.com/sirupsen/logrus"
    
    "your-module/internal/gateway"
    "your-module/internal/provider"
)

func main() {
    // Configure logging
    log.SetFormatter(&log.TextFormatter{
        FullTimestamp: true,
    })
    
    // Create provider client
    providerClient := provider.NewClient(provider.Config{
        OpenAIURL:    "http://localhost:8001",  // Mock provider
        AnthropicURL: "http://localhost:8002",  // Second mock (later)
        Timeout:      10 * time.Second,
    })
    
    // Create handler
    handler := gateway.NewHandler(providerClient)
    
    // Setup router
    r := gin.New()  // Don't use Default() - we add our own middleware
    r.Use(gateway.RequestIDMiddleware())
    r.Use(gateway.LoggingMiddleware())
    r.Use(gin.Recovery())  // Recover from panics
    
    // Routes
    r.POST("/v1/chat/completions", handler.ChatCompletion)
    r.GET("/health", handler.Health)
    
    log.Info("Gateway starting on :8080")
    r.Run(":8080")
}
```

### Step 2: Middleware

```go
// internal/gateway/middleware.go
package gateway

import (
    "github.com/gin-gonic/gin"
    "github.com/google/uuid"
    log "github.com/sirupsen/logrus"
    "time"
)

// RequestIDMiddleware generates unique ID for each request
func RequestIDMiddleware() gin.HandlerFunc {
    return func(c *gin.Context) {
        requestID := "req_" + uuid.New().String()[:8]
        c.Set("request_id", requestID)
        c.Header("X-Request-ID", requestID)
        c.Next()
    }
}

// LoggingMiddleware logs request start/end with timing
func LoggingMiddleware() gin.HandlerFunc {
    return func(c *gin.Context) {
        start := time.Now()
        requestID := c.GetString("request_id")
        
        log.WithFields(log.Fields{
            "request_id": requestID,
            "method":     c.Request.Method,
            "path":       c.Request.URL.Path,
            "event":      "started",
        }).Info("Request started")
        
        c.Next()  // Process request
        
        log.WithFields(log.Fields{
            "request_id": requestID,
            "status":     c.Writer.Status(),
            "latency_ms": time.Since(start).Milliseconds(),
            "event":      "completed",
        }).Info("Request completed")
    }
}
```

### Step 3: Handler

```go
// internal/gateway/handler.go
package gateway

import (
    "context"
    "net/http"
    "time"
    
    "github.com/gin-gonic/gin"
    log "github.com/sirupsen/logrus"
    
    "your-module/internal/models"
    "your-module/internal/provider"
)

type Handler struct {
    providerClient *provider.Client
}

func NewHandler(client *provider.Client) *Handler {
    return &Handler{providerClient: client}
}

func (h *Handler) ChatCompletion(c *gin.Context) {
    requestID := c.GetString("request_id")
    start := time.Now()
    
    // Parse request body
    var req models.Request
    if err := c.ShouldBindJSON(&req); err != nil {
        log.WithField("request_id", requestID).
            WithError(err).
            Warn("Invalid request body")
        c.JSON(http.StatusBadRequest, gin.H{
            "error": "Invalid request body: " + err.Error(),
        })
        return
    }
    
    log.WithFields(log.Fields{
        "request_id": requestID,
        "model":      req.Model,
        "event":      "validated",
    }).Info("Request validated")
    
    // Create context with request ID
    ctx := context.WithValue(c.Request.Context(), "request_id", requestID)
    
    // Call provider
    response, err := h.providerClient.Call(ctx, req)
    if err != nil {
        log.WithField("request_id", requestID).
            WithError(err).
            Error("Provider call failed")
        c.JSON(http.StatusBadGateway, gin.H{
            "error": "Provider error: " + err.Error(),
        })
        return
    }
    
    // Build response
    result := models.Response{
        RequestID:      requestID,
        Content:        response.Content,
        Model:          req.Model,
        Provider:       response.Provider,
        Attempts:       response.Attempts,
        TotalLatencyMs: time.Since(start).Milliseconds(),
        CreatedAt:      time.Now(),
    }
    
    c.JSON(http.StatusOK, result)
}

func (h *Handler) Health(c *gin.Context) {
    c.JSON(http.StatusOK, gin.H{"status": "healthy"})
}
```

### Step 4: Provider Client

```go
// internal/provider/client.go
package provider

import (
    "bytes"
    "context"
    "encoding/json"
    "fmt"
    "io"
    "net/http"
    "time"
    
    log "github.com/sirupsen/logrus"
    
    "your-module/internal/models"
)

type Config struct {
    OpenAIURL    string
    AnthropicURL string
    Timeout      time.Duration
}

type Client struct {
    httpClient *http.Client
    config     Config
}

func NewClient(config Config) *Client {
    return &Client{
        httpClient: &http.Client{
            Timeout: config.Timeout,
        },
        config: config,
    }
}

// ProviderResponse represents what we get back from provider
type ProviderResponse struct {
    Content  string
    Provider string
    Attempts int
}

func (c *Client) Call(ctx context.Context, req models.Request) (*ProviderResponse, error) {
    requestID := ctx.Value("request_id").(string)
    
    log.WithFields(log.Fields{
        "request_id": requestID,
        "provider":   "openai",
        "event":      "calling",
    }).Info("Calling provider")
    
    // Marshal request
    body, err := json.Marshal(req)
    if err != nil {
        return nil, fmt.Errorf("failed to marshal request: %w", err)
    }
    
    // Create HTTP request
    httpReq, err := http.NewRequestWithContext(
        ctx,
        "POST",
        c.config.OpenAIURL+"/v1/chat/completions",
        bytes.NewReader(body),
    )
    if err != nil {
        return nil, fmt.Errorf("failed to create request: %w", err)
    }
    httpReq.Header.Set("Content-Type", "application/json")
    
    // Make request
    start := time.Now()
    resp, err := c.httpClient.Do(httpReq)
    if err != nil {
        log.WithFields(log.Fields{
            "request_id": requestID,
            "error":      err.Error(),
            "event":      "provider_error",
        }).Warn("Provider request failed")
        return nil, fmt.Errorf("request failed: %w", err)
    }
    defer resp.Body.Close()
    
    latency := time.Since(start).Milliseconds()
    
    // Check status
    if resp.StatusCode != http.StatusOK {
        bodyBytes, _ := io.ReadAll(resp.Body)
        log.WithFields(log.Fields{
            "request_id":  requestID,
            "status_code": resp.StatusCode,
            "body":        string(bodyBytes),
            "event":       "provider_error",
        }).Warn("Provider returned error")
        return nil, fmt.Errorf("provider returned %d: %s", resp.StatusCode, string(bodyBytes))
    }
    
    // Parse response (OpenAI format)
    var openAIResp struct {
        Choices []struct {
            Message struct {
                Content string `json:"content"`
            } `json:"message"`
        } `json:"choices"`
    }
    
    if err := json.NewDecoder(resp.Body).Decode(&openAIResp); err != nil {
        return nil, fmt.Errorf("failed to decode response: %w", err)
    }
    
    content := ""
    if len(openAIResp.Choices) > 0 {
        content = openAIResp.Choices[0].Message.Content
    }
    
    log.WithFields(log.Fields{
        "request_id": requestID,
        "provider":   "openai",
        "latency_ms": latency,
        "event":      "success",
    }).Info("Provider call succeeded")
    
    return &ProviderResponse{
        Content:  content,
        Provider: "openai",
        Attempts: 1,
    }, nil
}
```

---

## Testing

### 1. Start Mock Provider (from M1)
```bash
cd cmd/mock-provider && go run main.go
# Running on :8001
```

### 2. Start Gateway
```bash
cd cmd/server && go run main.go
# Running on :8080
```

### 3. Test Request Through Gateway
```bash
curl -X POST http://localhost:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{"model": "gpt-4", "messages": [{"role": "user", "content": "Hello"}]}'
```

### Expected Response
```json
{
  "request_id": "req_a1b2c3d4",
  "content": "Hello! I'm a mock LLM response.",
  "model": "gpt-4",
  "provider": "openai",
  "attempts": 1,
  "total_latency_ms": 150,
  "created_at": "2024-12-17T10:00:00Z"
}
```

### Expected Logs
```
INFO Request started  event=started method=POST path=/v1/chat/completions request_id=req_a1b2c3d4
INFO Request validated  event=validated model=gpt-4 request_id=req_a1b2c3d4
INFO Calling provider  event=calling provider=openai request_id=req_a1b2c3d4
INFO Provider call succeeded  event=success latency_ms=150 provider=openai request_id=req_a1b2c3d4
INFO Request completed  event=completed latency_ms=155 request_id=req_a1b2c3d4 status=200
```

---

## Definition of Done

- [ ] Gateway starts on port 8080
- [ ] Request ID generated for each request
- [ ] Request ID visible in response header (X-Request-ID)
- [ ] Request ID visible in response body
- [ ] All logs include request_id field
- [ ] Request forwards to mock provider
- [ ] Response returned to client
- [ ] Health endpoint works: GET /health

