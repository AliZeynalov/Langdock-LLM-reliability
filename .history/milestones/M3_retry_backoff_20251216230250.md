# M3: Retry with Backoff

**Goal:** Add automatic retry logic with exponential backoff for transient failures.

**Time:** 3-4 hours  
**Output:** Failed requests automatically retry before giving up

---

## What We're Building

```
Request → Provider fails (timeout/5xx)
              ↓
         Wait 1s → Retry
              ↓
         Provider fails again
              ↓
         Wait 2s → Retry
              ↓
         Provider fails again
              ↓
         Wait 4s → Retry
              ↓
         Success (or give up after max attempts)
```

---

## Retry Strategy

| Error Type | Action | Reason |
|------------|--------|--------|
| Timeout | **Retry same provider** | Temporary network/server issue |
| 5xx (500, 502, 503, 504) | **Retry same provider** | Server temporarily overloaded |
| 429 Rate Limit | **Immediate failover** | Provider overloaded, try another |
| 4xx (400, 401, 403, 404) | **Fail fast** | Request is broken, won't help to retry |
| Success (2xx) | **Return response** | Done! |

---

## Key Concepts

### 1. Exponential Backoff

Wait time doubles after each failure:

```
Attempt 1: immediate
Attempt 2: wait 1 second
Attempt 3: wait 2 seconds
Attempt 4: wait 4 seconds (if max_attempts > 3)
```

Formula: `wait = base_delay * 2^(attempt - 1)`

### 2. Jitter (Optional but Recommended)

Add randomness to prevent "thundering herd" when many requests retry at the same time:

```go
// Without jitter: all retries happen at exactly 1s, 2s, 4s
// With jitter: retries spread out (0.8s-1.2s, 1.6s-2.4s, etc.)

jitter := rand.Float64() * 0.4 - 0.2  // -20% to +20%
wait := baseWait * (1 + jitter)
```

### 3. Context Cancellation

Respect context cancellation - if the client disconnects, stop retrying:

```go
select {
case <-time.After(waitDuration):
    // Continue with retry
case <-ctx.Done():
    // Client disconnected, stop
    return nil, ctx.Err()
}
```

---

## Implementation

### Update Provider Client

```go
// internal/provider/client.go

type RetryConfig struct {
    MaxAttempts int           // Max retry attempts (default: 3)
    BaseDelay   time.Duration // Initial delay (default: 1s)
    MaxDelay    time.Duration // Cap on delay (default: 10s)
}

type Client struct {
    httpClient  *http.Client
    config      Config
    retryConfig RetryConfig
}

func NewClient(config Config) *Client {
    return &Client{
        httpClient: &http.Client{
            Timeout: config.Timeout,
        },
        config: config,
        retryConfig: RetryConfig{
            MaxAttempts: 3,
            BaseDelay:   1 * time.Second,
            MaxDelay:    10 * time.Second,
        },
    }
}

func (c *Client) Call(ctx context.Context, req models.Request) (*ProviderResponse, error) {
    requestID := ctx.Value("request_id").(string)
    var lastErr error
    
    for attempt := 1; attempt <= c.retryConfig.MaxAttempts; attempt++ {
        log.WithFields(log.Fields{
            "request_id": requestID,
            "provider":   "openai",
            "attempt":    attempt,
            "event":      "attempt",
        }).Info("Attempting provider call")
        
        response, err := c.doRequest(ctx, req)
        
        if err == nil {
            // Success!
            log.WithFields(log.Fields{
                "request_id": requestID,
                "attempt":    attempt,
                "event":      "success",
            }).Info("Request succeeded")
            
            response.Attempts = attempt
            return response, nil
        }
        
        lastErr = err
        
        // Check if we should retry this error
        if !c.shouldRetry(err) {
            log.WithFields(log.Fields{
                "request_id": requestID,
                "error":      err.Error(),
                "event":      "no_retry",
            }).Warn("Error not retryable")
            return nil, err
        }
        
        // Don't wait after the last attempt
        if attempt == c.retryConfig.MaxAttempts {
            break
        }
        
        // Calculate backoff
        waitDuration := c.calculateBackoff(attempt)
        
        log.WithFields(log.Fields{
            "request_id": requestID,
            "attempt":    attempt,
            "wait_ms":    waitDuration.Milliseconds(),
            "event":      "backoff",
        }).Info("Waiting before retry")
        
        // Wait with context cancellation support
        select {
        case <-time.After(waitDuration):
            // Continue to next attempt
        case <-ctx.Done():
            return nil, ctx.Err()
        }
    }
    
    log.WithFields(log.Fields{
        "request_id":   requestID,
        "max_attempts": c.retryConfig.MaxAttempts,
        "event":        "exhausted",
    }).Warn("All retry attempts exhausted")
    
    return nil, fmt.Errorf("all %d attempts failed: %w", c.retryConfig.MaxAttempts, lastErr)
}

// doRequest makes a single HTTP request
func (c *Client) doRequest(ctx context.Context, req models.Request) (*ProviderResponse, error) {
    // Same code as before - make HTTP request, parse response
    // But now returns specific error types we can check
    
    body, err := json.Marshal(req)
    if err != nil {
        return nil, &RequestError{Type: "marshal", Err: err, Retryable: false}
    }
    
    httpReq, err := http.NewRequestWithContext(
        ctx,
        "POST",
        c.config.OpenAIURL+"/v1/chat/completions",
        bytes.NewReader(body),
    )
    if err != nil {
        return nil, &RequestError{Type: "create_request", Err: err, Retryable: false}
    }
    httpReq.Header.Set("Content-Type", "application/json")
    
    resp, err := c.httpClient.Do(httpReq)
    if err != nil {
        // Network error or timeout - retryable
        return nil, &RequestError{Type: "network", Err: err, Retryable: true}
    }
    defer resp.Body.Close()
    
    // Check status code
    if resp.StatusCode >= 500 {
        return nil, &RequestError{
            Type:       "server_error",
            StatusCode: resp.StatusCode,
            Retryable:  true,
        }
    }
    
    if resp.StatusCode == 429 {
        return nil, &RequestError{
            Type:       "rate_limit",
            StatusCode: 429,
            Retryable:  false,  // Will trigger failover instead
            Failover:   true,
        }
    }
    
    if resp.StatusCode >= 400 {
        return nil, &RequestError{
            Type:       "client_error",
            StatusCode: resp.StatusCode,
            Retryable:  false,
        }
    }
    
    // Parse successful response
    var openAIResp struct {
        Choices []struct {
            Message struct {
                Content string `json:"content"`
            } `json:"message"`
        } `json:"choices"`
    }
    
    if err := json.NewDecoder(resp.Body).Decode(&openAIResp); err != nil {
        return nil, &RequestError{Type: "decode", Err: err, Retryable: false}
    }
    
    content := ""
    if len(openAIResp.Choices) > 0 {
        content = openAIResp.Choices[0].Message.Content
    }
    
    return &ProviderResponse{
        Content:  content,
        Provider: "openai",
    }, nil
}

// shouldRetry determines if an error should trigger a retry
func (c *Client) shouldRetry(err error) bool {
    var reqErr *RequestError
    if errors.As(err, &reqErr) {
        return reqErr.Retryable
    }
    return false
}

// calculateBackoff returns wait duration for given attempt
func (c *Client) calculateBackoff(attempt int) time.Duration {
    // Exponential: 1s, 2s, 4s, 8s...
    wait := c.retryConfig.BaseDelay * time.Duration(1<<(attempt-1))
    
    // Cap at max delay
    if wait > c.retryConfig.MaxDelay {
        wait = c.retryConfig.MaxDelay
    }
    
    // Add jitter (-20% to +20%)
    jitter := 1.0 + (rand.Float64()*0.4 - 0.2)
    wait = time.Duration(float64(wait) * jitter)
    
    return wait
}
```

### Custom Error Type

```go
// internal/provider/errors.go

// RequestError represents an error from a provider request
type RequestError struct {
    Type       string // "network", "server_error", "rate_limit", "client_error"
    StatusCode int
    Err        error
    Retryable  bool
    Failover   bool   // Should trigger failover to another provider
}

func (e *RequestError) Error() string {
    if e.Err != nil {
        return fmt.Sprintf("%s: %v", e.Type, e.Err)
    }
    return fmt.Sprintf("%s: status %d", e.Type, e.StatusCode)
}

func (e *RequestError) Unwrap() error {
    return e.Err
}
```

---

## Testing

### Test 1: Retry on Timeout

```bash
# Mock provider with 5 second delay (timeout is 3 seconds)
# Start mock: go run cmd/mock-provider/main.go

# Request through gateway
curl -X POST "http://localhost:8080/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -d '{"model": "gpt-4", "messages": [{"role": "user", "content": "Hello"}]}'
```

But wait - we need to configure the mock to simulate timeout. Use:
```bash
# Configure mock to delay on first 2 requests, succeed on 3rd
# (We'll need to enhance mock provider to support this, or use separate endpoint)
```

### Test 2: Retry on 500

```bash
# Terminal 1: Start mock with fail=500 for first requests
curl -X POST "http://localhost:8001/v1/chat/completions?fail=500" ...

# Watch gateway logs show:
# attempt=1 → 500 → backoff 1s
# attempt=2 → 500 → backoff 2s  
# attempt=3 → 500 → exhausted
```

### Test 3: No Retry on 400

```bash
# This should fail immediately, no retries
curl -X POST "http://localhost:8080/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -d 'invalid json'

# Logs should show: no_retry, no backoff
```

---

## Expected Logs (Retry Scenario)

```
INFO  request_id=req_abc123 event=attempt provider=openai attempt=1
WARN  request_id=req_abc123 event=failed error="server_error: status 500" attempt=1
INFO  request_id=req_abc123 event=backoff wait_ms=1000
INFO  request_id=req_abc123 event=attempt provider=openai attempt=2
WARN  request_id=req_abc123 event=failed error="server_error: status 500" attempt=2
INFO  request_id=req_abc123 event=backoff wait_ms=2000
INFO  request_id=req_abc123 event=attempt provider=openai attempt=3
INFO  request_id=req_abc123 event=success attempt=3
```

---

## Definition of Done

- [ ] Retry on network timeout
- [ ] Retry on 5xx errors (500, 502, 503, 504)
- [ ] No retry on 4xx errors (except 429 handled separately)
- [ ] Exponential backoff: 1s → 2s → 4s
- [ ] Max 3 attempts by default
- [ ] Logs show each attempt with request_id
- [ ] Logs show backoff duration
- [ ] Context cancellation stops retries
- [ ] Response includes `attempts` count

